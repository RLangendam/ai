{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DweYe9FcbMK_"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:02.550317Z",
     "iopub.status.busy": "2020-11-18T02:25:02.549609Z",
     "iopub.status.idle": "2020-11-18T02:25:02.552499Z",
     "shell.execute_reply": "2020-11-18T02:25:02.551839Z"
    },
    "id": "AVV2e0XKbJeX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ap_W4aQcgNT"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/csv\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "This tutorial provides examples of how to use CSV data with TensorFlow.\n",
    "\n",
    "There are two main parts to this:\n",
    "\n",
    "1. **Loading the data off disk**\n",
    "2. **Pre-processing it into a form suitable for training.**\n",
    "\n",
    "This tutorial focuses on the loading, and gives some quick examples of preprocessing. For a tutorial that focuses on the preprocessing aspect see the [preprocessing layers guide](https://www.tensorflow.org/guide/keras/preprocessing_layers#quick_recipes) and [tutorial](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:02.557582Z",
     "iopub.status.busy": "2020-11-18T02:25:02.556911Z",
     "iopub.status.idle": "2020-11-18T02:25:09.073474Z",
     "shell.execute_reply": "2020-11-18T02:25:09.072853Z"
    },
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZhJYbJxHNGJ"
   },
   "source": [
    "## In memory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ny5TEgcmHjVx"
   },
   "source": [
    "For any small CSV dataset the simplest way to train a TensorFlow model on it is to load it into memory as a pandas Dataframe or a NumPy array. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgpBOuU8PGFf"
   },
   "source": [
    "A relatively simple example is the [abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone). \n",
    "\n",
    "* The dataset is small. \n",
    "* All the input features are all limited-range floating point values. \n",
    "\n",
    "Here is how to download the data into a [Pandas `DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:09.079454Z",
     "iopub.status.busy": "2020-11-18T02:25:09.078772Z",
     "iopub.status.idle": "2020-11-18T02:25:09.373995Z",
     "shell.execute_reply": "2020-11-18T02:25:09.374673Z"
    },
    "id": "IZVExo9DKoNz"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Shucked weight</th>\n      <th>Viscera weight</th>\n      <th>Shell weight</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.435</td>\n      <td>0.335</td>\n      <td>0.110</td>\n      <td>0.334</td>\n      <td>0.1355</td>\n      <td>0.0775</td>\n      <td>0.0965</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.585</td>\n      <td>0.450</td>\n      <td>0.125</td>\n      <td>0.874</td>\n      <td>0.3545</td>\n      <td>0.2075</td>\n      <td>0.2250</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.655</td>\n      <td>0.510</td>\n      <td>0.160</td>\n      <td>1.092</td>\n      <td>0.3960</td>\n      <td>0.2825</td>\n      <td>0.3700</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.545</td>\n      <td>0.425</td>\n      <td>0.125</td>\n      <td>0.768</td>\n      <td>0.2940</td>\n      <td>0.1495</td>\n      <td>0.2600</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.545</td>\n      <td>0.420</td>\n      <td>0.130</td>\n      <td>0.879</td>\n      <td>0.3740</td>\n      <td>0.1695</td>\n      <td>0.2300</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP22mdyPQ1_t"
   },
   "source": [
    "The dataset contains a set of measurements of [abalone](https://en.wikipedia.org/wiki/Abalone), a type of sea snail. \n",
    "\n",
    "![an abalone shell](https://tensorflow.org/images/abalone_shell.jpg)\n",
    "\n",
    " [“Abalone shell”](https://www.flickr.com/photos/thenickster/16641048623/) (by [Nicki Dugan Pogue](https://www.flickr.com/photos/thenickster/), CC BY-SA 2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlfGrk_9N-wf"
   },
   "source": [
    "The nominal task for this dataset is to predict the age from the other measurements, so separate the features and labels for training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:09.380081Z",
     "iopub.status.busy": "2020-11-18T02:25:09.379305Z",
     "iopub.status.idle": "2020-11-18T02:25:09.381816Z",
     "shell.execute_reply": "2020-11-18T02:25:09.381245Z"
    },
    "id": "udOnDJOxNi7p"
   },
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seK9n71-UBfT"
   },
   "source": [
    "For this dataset you will treat all features identically. Pack the features into a single NumPy array.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:09.385937Z",
     "iopub.status.busy": "2020-11-18T02:25:09.385204Z",
     "iopub.status.idle": "2020-11-18T02:25:09.389786Z",
     "shell.execute_reply": "2020-11-18T02:25:09.389175Z"
    },
    "id": "Dp3N5McbUMwb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C1yFOxLOdxh"
   },
   "source": [
    "Next make a regression model predict the age. Since there is only a single input tensor, a `keras.Sequential` model is sufficient here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:09.394655Z",
     "iopub.status.busy": "2020-11-18T02:25:09.393990Z",
     "iopub.status.idle": "2020-11-18T02:25:17.821364Z",
     "shell.execute_reply": "2020-11-18T02:25:17.821827Z"
    },
    "id": "d8zzNrZqOmfB"
   },
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6IWeP78O2wE"
   },
   "source": [
    "To train that model, pass the features and labels to `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:17.828227Z",
     "iopub.status.busy": "2020-11-18T02:25:17.827505Z",
     "iopub.status.idle": "2020-11-18T02:25:19.997496Z",
     "shell.execute_reply": "2020-11-18T02:25:19.996866Z"
    },
    "id": "uZdpCD92SN3Z"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 1s 2ms/step - loss: 89.7557\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 17.5535\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5330\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.2757\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.1461\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.4443\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.1466\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.9235\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.7613\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.5905\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22485808520>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GapLOj1OOTQH"
   },
   "source": [
    "You have just seen the most basic way to train a model using CSV data. Next, you will learn how to apply preprocessing to normalize numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B87Rd1SOUv02"
   },
   "source": [
    "## Basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCrB2Jd-U0Vt"
   },
   "source": [
    "It's good practice to normalize the inputs to your model. The `experimental.preprocessing` layers provide a convenient way to build this normalization into your model. \n",
    "\n",
    "The layer will precompute the mean and variance of each column, and use these to normalize the data.\n",
    "\n",
    "First you create the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:20.006201Z",
     "iopub.status.busy": "2020-11-18T02:25:20.005537Z",
     "iopub.status.idle": "2020-11-18T02:25:20.008363Z",
     "shell.execute_reply": "2020-11-18T02:25:20.007801Z"
    },
    "id": "H2WQpDU5VRk7"
   },
   "outputs": [],
   "source": [
    "normalize = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGgEZE-7Vpt6"
   },
   "source": [
    "Then you use the `Normalization.adapt()` method to adapt the normalization layer to your data.\n",
    "\n",
    "Note: Only use your training data to `.adapt()` preprocessing layers. Do not use your validation or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:20.013472Z",
     "iopub.status.busy": "2020-11-18T02:25:20.012772Z",
     "iopub.status.idle": "2020-11-18T02:25:20.021125Z",
     "shell.execute_reply": "2020-11-18T02:25:20.020609Z"
    },
    "id": "2WgOPIiOVpLg"
   },
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6vh0byV7cE"
   },
   "source": [
    "Then use the normalization layer in your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:20.028958Z",
     "iopub.status.busy": "2020-11-18T02:25:20.028221Z",
     "iopub.status.idle": "2020-11-18T02:25:21.916860Z",
     "shell.execute_reply": "2020-11-18T02:25:21.917310Z"
    },
    "id": "quPcZ9dTWA9A"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 98.2287\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 64.3797\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 21.7732\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.8911\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.6727\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.7233\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.7894\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.8402\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.6056\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.9578\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2249a7344c0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Mixed data types\n",
    "\n",
    "The \"Titanic\" dataset contains information about the passengers on the Titanic. The nominal task on this dataset is to predict who survived. \n",
    "\n",
    "![The Titanic](images/csv/Titanic.jpg)\n",
    "\n",
    "Image [from Wikimedia](https://commons.wikimedia.org/wiki/File:RMS_Titanic_3.jpg)\n",
    "\n",
    "The raw data can easily be loaded as a Pandas `DataFrame`, but is not immediately usable as input to a TensorFlow model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:21.921983Z",
     "iopub.status.busy": "2020-11-18T02:25:21.921284Z",
     "iopub.status.idle": "2020-11-18T02:25:22.116327Z",
     "shell.execute_reply": "2020-11-18T02:25:22.115729Z"
    },
    "id": "GS-dBMpuYMnz"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>n_siblings_spouses</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.4583</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Queenstown</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.121506Z",
     "iopub.status.busy": "2020-11-18T02:25:22.120814Z",
     "iopub.status.idle": "2020-11-18T02:25:22.122677Z",
     "shell.execute_reply": "2020-11-18T02:25:22.123094Z"
    },
    "id": "D8rCGIK1ZzKx"
   },
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urHOwpCDYtcI"
   },
   "source": [
    "Because of the different data types and ranges you can't simply stack the features into  NumPy array and pass it to a `keras.Sequential` model. Each column needs to be handled individually. \n",
    "\n",
    "As one option, you could preprocess your data offline (using any tool you like) to convert categorical columns to numeric columns, then pass the processed output to your TensorFlow model. The disadvantage to that approach is that if you save and export your model the preprocessing is not saved with it. The `experimental.preprocessing` layers avoid this problem because they're part of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bta4Sx0Zau5v"
   },
   "source": [
    "In this example, you'll build a model that implements the preprocessing logic using [Keras functional API](https://www.tensorflow.org/guide/keras/functional.ipynb). You could also do it by [subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n",
    "\n",
    "The functional API operates on \"symbolic\" tensors. Normal \"eager\" tensors have a value. In contrast these \"symbolic\" tensors do not. Instead they keep track of which operations are run on them, and build representation of the calculation, that you can run later. Here's a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.131544Z",
     "iopub.status.busy": "2020-11-18T02:25:22.130690Z",
     "iopub.status.idle": "2020-11-18T02:25:22.135576Z",
     "shell.execute_reply": "2020-11-18T02:25:22.135018Z"
    },
    "id": "730F16_97D-3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Do a calculation using is\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.141203Z",
     "iopub.status.busy": "2020-11-18T02:25:22.140544Z",
     "iopub.status.idle": "2020-11-18T02:25:22.155019Z",
     "shell.execute_reply": "2020-11-18T02:25:22.154401Z"
    },
    "id": "RtcNXWB18kMJ"
   },
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.159395Z",
     "iopub.status.busy": "2020-11-18T02:25:22.158701Z",
     "iopub.status.idle": "2020-11-18T02:25:22.202260Z",
     "shell.execute_reply": "2020-11-18T02:25:22.201663Z"
    },
    "id": "fUGQOUqZ8sa-"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.0\n5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNS9lT7f6_U2"
   },
   "source": [
    "To build the preprocessing model, start by building a set of symbolic `keras.Input` objects, matching the names and data-types of the CSV columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.209337Z",
     "iopub.status.busy": "2020-11-18T02:25:22.207777Z",
     "iopub.status.idle": "2020-11-18T02:25:22.222449Z",
     "shell.execute_reply": "2020-11-18T02:25:22.221847Z"
    },
    "id": "5WODe_1da3yw"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'sex')>,\n",
       " 'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'n_siblings_spouses': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'n_siblings_spouses')>,\n",
       " 'parch': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'parch')>,\n",
       " 'fare': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'fare')>,\n",
       " 'class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'class')>,\n",
       " 'deck': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'deck')>,\n",
       " 'embark_town': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'embark_town')>,\n",
       " 'alone': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'alone')>}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaheJFmymq8l"
   },
   "source": [
    "The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.233673Z",
     "iopub.status.busy": "2020-11-18T02:25:22.229394Z",
     "iopub.status.idle": "2020-11-18T02:25:22.247070Z",
     "shell.execute_reply": "2020-11-18T02:25:22.246515Z"
    },
    "id": "wPRC_E6rkp8D"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'normalization_1')>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JoR45Uj712l"
   },
   "source": [
    "Collect all the symbolic preprocessing results, to concatenate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.251105Z",
     "iopub.status.busy": "2020-11-18T02:25:22.250453Z",
     "iopub.status.idle": "2020-11-18T02:25:22.252365Z",
     "shell.execute_reply": "2020-11-18T02:25:22.252767Z"
    },
    "id": "M7jIJw5XntdN"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Hryylyosfm"
   },
   "source": [
    "For the string inputs use the `preprocessing.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `preprocessing.CategoryEncoding` to convert the indexes into `float32` data appropriate for the model. \n",
    "\n",
    "The default settings for the `preprocessing.CategoryEncoding` layer create a one-hot vector for each input. A `layers.Embedding` would also work. See the [preprocessing layers guide](https://www.tensorflow.org/guide/keras/preprocessing_layers#quick_recipes) and [tutorial](../structured_data/preprocessing_layers.ipynb) for more on this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.264036Z",
     "iopub.status.busy": "2020-11-18T02:25:22.263330Z",
     "iopub.status.idle": "2020-11-18T02:25:22.339767Z",
     "shell.execute_reply": "2020-11-18T02:25:22.340246Z"
    },
    "id": "79fi1Cgan2YV"
   },
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  \n",
    "  lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnhv0T7itnc7"
   },
   "source": [
    "With the collection of `inputs` and `processed_inputs`, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.349049Z",
     "iopub.status.busy": "2020-11-18T02:25:22.348357Z",
     "iopub.status.idle": "2020-11-18T02:25:22.512085Z",
     "shell.execute_reply": "2020-11-18T02:25:22.512545Z"
    },
    "id": "XJRzUTe8ukXc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNHxrNW8vdda"
   },
   "source": [
    "This `model` just contains the input preprocessing. You can run it to see what it does to your data. Keras models don't automatically convert Pandas `DataFrames` because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So convert it to a dictionary of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.518177Z",
     "iopub.status.busy": "2020-11-18T02:25:22.517469Z",
     "iopub.status.idle": "2020-11-18T02:25:22.519814Z",
     "shell.execute_reply": "2020-11-18T02:25:22.519274Z"
    },
    "id": "5YjdYyMEacwQ"
   },
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nKJYoPByada"
   },
   "source": [
    "Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.525506Z",
     "iopub.status.busy": "2020-11-18T02:25:22.524820Z",
     "iopub.status.idle": "2020-11-18T02:25:22.541379Z",
     "shell.execute_reply": "2020-11-18T02:25:22.540868Z"
    },
    "id": "SjnmU8PSv8T3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkBf4LvmzMDp"
   },
   "source": [
    "Now build the model on top of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.550741Z",
     "iopub.status.busy": "2020-11-18T02:25:22.550065Z",
     "iopub.status.idle": "2020-11-18T02:25:22.634595Z",
     "shell.execute_reply": "2020-11-18T02:25:22.633977Z"
    },
    "id": "coIPtGaCzUV7"
   },
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK5uBQQF2KbZ"
   },
   "source": [
    "When you train the model, pass the dictionary of features as `x`, and the label as `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:22.639734Z",
     "iopub.status.busy": "2020-11-18T02:25:22.638989Z",
     "iopub.status.idle": "2020-11-18T02:25:23.769609Z",
     "shell.execute_reply": "2020-11-18T02:25:23.770038Z"
    },
    "id": "D1gVfwJ61ejz"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 5ms/step - loss: 0.6854\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5440\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4831\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4719\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4527\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4258\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4347\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4335\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4143\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4074\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22662ef7b50>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgJarZk3bfH"
   },
   "source": [
    "Since the preprocessing is part of the model, you can save the model and reload it somewhere else and get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:23.778693Z",
     "iopub.status.busy": "2020-11-18T02:25:23.777969Z",
     "iopub.status.idle": "2020-11-18T02:25:26.926250Z",
     "shell.execute_reply": "2020-11-18T02:25:26.925671Z"
    },
    "id": "Ay-8ymNA2ZCh"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x0000022681D02670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.931913Z",
     "iopub.status.busy": "2020-11-18T02:25:26.931140Z",
     "iopub.status.idle": "2020-11-18T02:25:26.955221Z",
     "shell.execute_reply": "2020-11-18T02:25:26.955693Z"
    },
    "id": "Qm6jMTpD20lK"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([[-1.911]], shape=(1, 1), dtype=float32)\ntf.Tensor([[-1.911]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VsPlxIRZpXf"
   },
   "source": [
    "## Using tf.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyVDCwGzR5HW"
   },
   "source": [
    "In the previous section you relied on the model's built-in data shuffling and batching while training the model. \n",
    "\n",
    "If you need more control over the input data pipeline or need to use data that doesn't easily fit into memory: use `tf.data`. \n",
    "\n",
    "For more examples see the [tf.data guide](../../guide/data.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP5Y1jM2Sor0"
   },
   "source": [
    "### On in memory data\n",
    "\n",
    "As a first example of applying `tf.data` to CSV data consider the following code to manually slice up the dictionary of features from the previous section. For each index, it takes that index for each feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.960794Z",
     "iopub.status.busy": "2020-11-18T02:25:26.960128Z",
     "iopub.status.idle": "2020-11-18T02:25:26.962013Z",
     "shell.execute_reply": "2020-11-18T02:25:26.962476Z"
    },
    "id": "i8wE-MVuVu7_"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ3RTbS9YEal"
   },
   "source": [
    "Run this and print the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.967177Z",
     "iopub.status.busy": "2020-11-18T02:25:26.966521Z",
     "iopub.status.idle": "2020-11-18T02:25:26.969325Z",
     "shell.execute_reply": "2020-11-18T02:25:26.969746Z"
    },
    "id": "Wwq8XK88WwFk"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sex                : male\nage                : 22.0\nn_siblings_spouses : 1\nparch              : 0\nfare               : 7.25\nclass              : Third\ndeck               : unknown\nembark_town        : Southampton\nalone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvp8Dct6YOIE"
   },
   "source": [
    "The most basic `tf.data.Dataset` in memory data loader is the `Dataset.from_tensor_slices` constructor. This returns a `tf.data.Dataset` that implements a generalized version of the above `slices` function, in TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.975375Z",
     "iopub.status.busy": "2020-11-18T02:25:26.974600Z",
     "iopub.status.idle": "2020-11-18T02:25:26.976691Z",
     "shell.execute_reply": "2020-11-18T02:25:26.977117Z"
    },
    "id": "2gEJthslYxeV"
   },
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZC0rTpMZMZK"
   },
   "source": [
    "You can iterate over a `tf.data.Dataset` like any other python iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.981673Z",
     "iopub.status.busy": "2020-11-18T02:25:26.981029Z",
     "iopub.status.idle": "2020-11-18T02:25:26.987555Z",
     "shell.execute_reply": "2020-11-18T02:25:26.988075Z"
    },
    "id": "gOHbiefaY4ag"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sex                : b'male'\nage                : 22.0\nn_siblings_spouses : 1\nparch              : 0\nfare               : 7.25\nclass              : b'Third'\ndeck               : b'unknown'\nembark_town        : b'Southampton'\nalone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwcFoVJWZY5F"
   },
   "source": [
    "The `from_tensor_slices` function can handle any structure of nested dictionaries or tuples. The following code makes a dataset of `(features_dict, labels)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:26.994234Z",
     "iopub.status.busy": "2020-11-18T02:25:26.993582Z",
     "iopub.status.idle": "2020-11-18T02:25:26.996320Z",
     "shell.execute_reply": "2020-11-18T02:25:26.995780Z"
    },
    "id": "xIHGBy76Zcrx"
   },
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQwxitt8c2GK"
   },
   "source": [
    "To train a model using this `Dataset`, you'll need to at least `shuffle` and `batch` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.000469Z",
     "iopub.status.busy": "2020-11-18T02:25:26.999786Z",
     "iopub.status.idle": "2020-11-18T02:25:27.003092Z",
     "shell.execute_reply": "2020-11-18T02:25:27.002495Z"
    },
    "id": "SbJcbldhddeC"
   },
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4FRqhRFuoJx"
   },
   "source": [
    "Instead of passing `features` and `labels` to `Model.fit`, you pass the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.007460Z",
     "iopub.status.busy": "2020-11-18T02:25:27.006794Z",
     "iopub.status.idle": "2020-11-18T02:25:27.717070Z",
     "shell.execute_reply": "2020-11-18T02:25:27.716428Z"
    },
    "id": "8yXkNPumdBtB"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4208\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4219\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4188\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4191\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4194\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x226815d0fd0>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXuibiv9exT7"
   },
   "source": [
    "### From a single file\n",
    "\n",
    "So far this tutorial has worked with in-memory data. `tf.data` is a highly scalable toolkit for building data pipelines, and provides a few functions for dealing loading CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.722207Z",
     "iopub.status.busy": "2020-11-18T02:25:27.721404Z",
     "iopub.status.idle": "2020-11-18T02:25:27.733428Z",
     "shell.execute_reply": "2020-11-18T02:25:27.732868Z"
    },
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now read the CSV data from the file and create a `tf.data.Dataset`. \n",
    "\n",
    "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.737873Z",
     "iopub.status.busy": "2020-11-18T02:25:27.737173Z",
     "iopub.status.idle": "2020-11-18T02:25:27.781665Z",
     "shell.execute_reply": "2020-11-18T02:25:27.782137Z"
    },
    "id": "yIbUscB9sqha"
   },
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf3v3BKgy4AG"
   },
   "source": [
    "This function includes many convenient features so the data is easy to work with. This includes:\n",
    "\n",
    "* Using the column headers as dictionary keys.\n",
    "* Automatically determining the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.787777Z",
     "iopub.status.busy": "2020-11-18T02:25:27.787073Z",
     "iopub.status.idle": "2020-11-18T02:25:27.821789Z",
     "shell.execute_reply": "2020-11-18T02:25:27.821223Z"
    },
    "id": "v4oMO9MIxgTG"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'male' b'female']\nage                 : [32. 51. 44. 17. 45.]\nn_siblings_spouses  : [0 0 0 0 1]\nparch               : [0 0 1 2 1]\nfare                : [  8.363  26.55   16.1   110.883  26.25 ]\nclass               : [b'Third' b'First' b'Third' b'First' b'Second']\ndeck                : [b'unknown' b'E' b'unknown' b'C' b'unknown']\nembark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\nalone               : [b'y' b'y' b'n' b'n' b'n']\n\nlabel               : [0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-TgA6o2Ja6U"
   },
   "source": [
    "Note: if you run the above cell twice it will produce different results. The default settings for `make_csv_dataset` include `shuffle_buffer_size=1000`, which is more than sufficient for this small dataset, but may not be for a real-world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6uviU_KCCWD"
   },
   "source": [
    "It can also decompress the data on the fly. Here's a gzipped CSV file containing the [metro interstate traffic dataset](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume)\n",
    "\n",
    "![A traffic jam.](images/csv/traffic.jpg)\n",
    "\n",
    "Image [from Wikimedia](https://commons.wikimedia.org/wiki/File:Trafficjam.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:27.826297Z",
     "iopub.status.busy": "2020-11-18T02:25:27.825638Z",
     "iopub.status.idle": "2020-11-18T02:25:29.282712Z",
     "shell.execute_reply": "2020-11-18T02:25:29.283124Z"
    },
    "id": "kT7oZI2E46Q8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      "409600/405373 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-IOsFHbCw0i"
   },
   "source": [
    "Set the `compression_type` argument to read directly from the compressed file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:29.288577Z",
     "iopub.status.busy": "2020-11-18T02:25:29.287908Z",
     "iopub.status.idle": "2020-11-18T02:25:29.478072Z",
     "shell.execute_reply": "2020-11-18T02:25:29.477419Z"
    },
    "id": "ar0MPEVJ5NeA"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\ntemp                : [273.9  281.15 296.   274.62 275.39]\nrain_1h             : [0. 0. 0. 0. 0.]\nsnow_1h             : [0. 0. 0. 0. 0.]\nclouds_all          : [90  1  0 75 75]\nweather_main        : [b'Snow' b'Clear' b'Clear' b'Haze' b'Clouds']\nweather_description : [b'heavy snow' b'sky is clear' b'Sky is Clear' b'haze' b'broken clouds']\ndate_time           : [b'2013-04-12 12:00:00' b'2013-11-15 19:00:00' b'2013-08-14 18:00:00'\n b'2013-02-27 14:00:00' b'2013-11-14 05:00:00']\n\nlabel               : [5393 3659 4863 5199 2932]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p12Y6tGq8D6M"
   },
   "source": [
    "Note: If you need to parse those date-time strings in the `tf.data` pipeline you can use `tfa.text.parse_time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtrAXzYGP3l0"
   },
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN2dL_LRP83r"
   },
   "source": [
    "There is some overhead to parsing the csv data. For small models this can be the bottleneck in training.\n",
    "\n",
    "Depending on your use case it may be a good idea to use `Dataset.cache` or `data.experimental.snapshot` so that the csv data is only parsed on the first epoch. \n",
    "\n",
    "The main difference between the `cache` and `snapshot` methods is that `cache` files can only be used by the TensorFlow process that created them, but `snapshot` files can be read by other processes.\n",
    "\n",
    "For example, iterating over the `traffic_volume_csv_gz_ds` 20 times, takes ~15 seconds without caching, or ~2s with caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:29.484012Z",
     "iopub.status.busy": "2020-11-18T02:25:29.483215Z",
     "iopub.status.idle": "2020-11-18T02:25:41.846971Z",
     "shell.execute_reply": "2020-11-18T02:25:41.846295Z"
    },
    "id": "Qk38Sw4MO4eh"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...............................................................................................\n",
      "Wall time: 8.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN3HtDONh5TX"
   },
   "source": [
    "Note: `Dataset.cache`  stores the data form the first epoch and replays it in order. So using `.cache` disables any shuffles earlier in the pipeline. Below the `.shuffle` is added back in after `.cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:41.852341Z",
     "iopub.status.busy": "2020-11-18T02:25:41.851567Z",
     "iopub.status.idle": "2020-11-18T02:25:43.174624Z",
     "shell.execute_reply": "2020-11-18T02:25:43.175048Z"
    },
    "id": "r5Jj72MrPbnh"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...............................................................................................\n",
      "Wall time: 928 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN7uUBjmgNZ9"
   },
   "source": [
    "Note: `snapshot` files are meant for *temporary* storage of a dataset while in use. This is *not* a format for long term storage. The file format is considered an internal detail, and not guaranteed between TensorFlow versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:43.182622Z",
     "iopub.status.busy": "2020-11-18T02:25:43.181920Z",
     "iopub.status.idle": "2020-11-18T02:25:44.824727Z",
     "shell.execute_reply": "2020-11-18T02:25:44.824092Z"
    },
    "id": "PHGD1E8ktUvW"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...............................................................................................\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUSSegnMCGRz"
   },
   "source": [
    "If your data loading is slowed by loading csv files, and `cache` and `snapshot` are insufficient for your use case, consider re-encoding your data into a more streamlined format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0iGXv9pC5kr"
   },
   "source": [
    "### Multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FFzHQrCDH4w"
   },
   "source": [
    "All the examples so far in this section could easily be done without `tf.data`. One place where `tf.data` can really simplify things is when dealing with collections of files.\n",
    "\n",
    "For example, the [character font images](https://archive.ics.uci.edu/ml/datasets/Character+Font+Images) dataset is distributed as a collection of csv files, one per font.\n",
    "\n",
    "![Fonts](images/csv/fonts.jpg)\n",
    "\n",
    "Image by <a href=\"https://pixabay.com/users/wilhei-883152/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=705667\">Willi Heidelbach</a> from <a href=\"https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=705667\">Pixabay</a>\n",
    "\n",
    "Download the dataset, and have a look at the files inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:44.830219Z",
     "iopub.status.busy": "2020-11-18T02:25:44.829512Z",
     "iopub.status.idle": "2020-11-18T02:25:58.935914Z",
     "shell.execute_reply": "2020-11-18T02:25:58.935204Z"
    },
    "id": "RmVknMdJh5ks"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:58.941029Z",
     "iopub.status.busy": "2020-11-18T02:25:58.940279Z",
     "iopub.status.idle": "2020-11-18T02:25:58.945430Z",
     "shell.execute_reply": "2020-11-18T02:25:58.944927Z"
    },
    "id": "xsDlMCnyi55e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fonts\\\\AGENCY.csv',\n",
       " 'fonts\\\\ARIAL.csv',\n",
       " 'fonts\\\\BAITI.csv',\n",
       " 'fonts\\\\BANKGOTHIC.csv',\n",
       " 'fonts\\\\BASKERVILLE.csv',\n",
       " 'fonts\\\\BAUHAUS.csv',\n",
       " 'fonts\\\\BELL.csv',\n",
       " 'fonts\\\\BERLIN.csv',\n",
       " 'fonts\\\\BERNARD.csv',\n",
       " 'fonts\\\\BITSTREAMVERA.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:58.949567Z",
     "iopub.status.busy": "2020-11-18T02:25:58.948925Z",
     "iopub.status.idle": "2020-11-18T02:25:58.952026Z",
     "shell.execute_reply": "2020-11-18T02:25:58.951453Z"
    },
    "id": "lRAEJx9ROAGl"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19Udrw9iG-FS"
   },
   "source": [
    "When dealing with a bunch of files you can pass a glob-style `file_pattern` to the `experimental.make_csv_dataset` function. The order of the files is shuffled each iteration.\n",
    "\n",
    "Use the `num_parallel_reads` argument to set how many files are read in parallel and interleaved together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:58.956788Z",
     "iopub.status.busy": "2020-11-18T02:25:58.955863Z",
     "iopub.status.idle": "2020-11-18T02:25:59.963440Z",
     "shell.execute_reply": "2020-11-18T02:25:59.962819Z"
    },
    "id": "6TSUNdT6iG58"
   },
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMoexinLHYFa"
   },
   "source": [
    "These csv files have the images flattened out into a single row. The column names are formatted `r{row}c{column}`. Here's the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:25:59.971449Z",
     "iopub.status.busy": "2020-11-18T02:25:59.970778Z",
     "iopub.status.idle": "2020-11-18T02:26:01.522053Z",
     "shell.execute_reply": "2020-11-18T02:26:01.522480Z"
    },
    "id": "RmFvBWxxi3pq"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "font                : [b'CITYBLUEPRINT' b'CITYBLUEPRINT' b'BUXTON' b'MAIANDRA' b'OCRB' b'TAHOMA'\n",
      " b'FRENCH' b'ERAS' b'FRENCH' b'PLAYBILL']\n",
      "fontVariant         : [b'CITYBLUEPRINT' b'CITYBLUEPRINT' b'BUXTON SKETCH' b'MAIANDRA GD'\n",
      " b'scanned' b'TAHOMA' b'FRENCH SCRIPT MT' b'ERAS MEDIUM ITC'\n",
      " b'FRENCH SCRIPT MT' b'PLAYBILL']\n",
      "m_label             : [61543 61635  8976   192    35 64290   199   229   353    80]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 0 0 0 0 0 1 1 0 1]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [61 26 54 23  0 46 32 31 48 30]\n",
      "m_left              : [21 18 23 22  0 21 26 24 20 21]\n",
      "originalH           : [43 65 19 62 46 41 59 50 29 45]\n",
      "originalW           : [26 36 25 42 21 44 41 37 18 32]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1   1   1 255   1   1   1   1]\n",
      "r0c1                : [  1   1   1   1   1 255   1   1   1   1]\n",
      "r0c2                : [  1   1   1   1   1 255   1   1 137   1]\n",
      "r0c3                : [  1   3 205   1   1 255   1   1 229   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "  for i, (name, value) in enumerate(features.items()):\n",
    "    if i>15:\n",
    "      break\n",
    "    print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrC3sKdeOhb5"
   },
   "source": [
    "#### Optional: Packing fields\n",
    "\n",
    "You probably don't want to work with each pixel in separate columns like this. Before trying to use this dataset be sure to pack the pixels into an image-tensor. \n",
    "\n",
    "Here is code that parses the column names to build images for each example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:01.529278Z",
     "iopub.status.busy": "2020-11-18T02:26:01.528556Z",
     "iopub.status.idle": "2020-11-18T02:26:01.530928Z",
     "shell.execute_reply": "2020-11-18T02:26:01.530423Z"
    },
    "id": "hct5EMEWNyfH"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "  image = [None]*400\n",
    "  new_feats = {}\n",
    "\n",
    "  for name, value in features.items():\n",
    "    match = re.match('r(\\d+)c(\\d+)', name)\n",
    "    if match:\n",
    "      image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "    else:\n",
    "      new_feats[name] = value\n",
    "\n",
    "  image = tf.stack(image, axis=0)\n",
    "  image = tf.reshape(image, [20, 20, -1])\n",
    "  new_feats['image'] = image\n",
    "\n",
    "  return new_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61qy8utAwARP"
   },
   "source": [
    "Apply that function to each batch in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:01.538611Z",
     "iopub.status.busy": "2020-11-18T02:26:01.537930Z",
     "iopub.status.idle": "2020-11-18T02:26:03.381449Z",
     "shell.execute_reply": "2020-11-18T02:26:03.381911Z"
    },
    "id": "DJnnfIW9baE4"
   },
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ThqrthGwHSm"
   },
   "source": [
    "Plot the resulting images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:03.388936Z",
     "iopub.status.busy": "2020-11-18T02:26:03.388210Z",
     "iopub.status.idle": "2020-11-18T02:26:04.420202Z",
     "shell.execute_reply": "2020-11-18T02:26:04.420629Z"
    },
    "id": "I5dcey31T_tk"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 9 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"355.678125pt\" version=\"1.1\" viewBox=\"0 0 346.658824 355.678125\" width=\"346.658824pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-02-26T23:58:38.340620</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 355.678125 \r\nL 346.658824 355.678125 \r\nL 346.658824 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#pbba00f5536)\">\r\n    <image height=\"96\" id=\"imageeea6a1baf8\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-22.247537\"/>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <!-- 0 -->\r\n    <g transform=\"translate(51.347206 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-48\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g clip-path=\"url(#p32c94287bf)\">\r\n    <image height=\"96\" id=\"image804cbd19dd\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"125.364706\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAD3UlEQVR4nO3d32vVdRzH8fOdOqJlrkEGrSwh+gE1SgiyJIgmVFBRLeqmMLrp126KLoPoqgu3mwi7CnPQTSEE0X03aWAXemGEUGZWgv0YiNZynfUfvAdt3/P6uj0ety/Pd1/lyefiwxk2E9OzS73CwpZq7fXe3bO/3B8buVA/gHVtKP0CrG8CJEqARAmQKAESJUCiBEhUM9lMlfeAyznx0Y5y/373hyt5fO+mj18q91tmTq7o+evdb5Pby/3s7oVyP/zAe+W+dcNIuTsBiRIgUQIkSoBECZAoARIlQKI2pl9gORv+asp98dczA3qTtWl0rv73G52rP//E06+X+4G9M+XuBCRKgEQJkCgBEiVAogRIlACJ6vw9IN12xSdfl/vDT71S7k5AogRIlACJEiBRAiRKgEQJkCgBEiVAogRIlACJEiBRAiRKgEQJkCjfB6RV2589Vu5OQKIESJQAiRIgUQIkSoBECZAo94Add/blneV+9b5DA3qTdjgBiRIgUQIkSoBECZAoARIlQKLcA4YNTdxa7rtePFLu3+1bzbcZPCcgUQIkSoBECZAoARIlQKIESFTn7wHfmPqs3D+/f2JAb9KO2688Xu57xurv+0337lvN1xk4JyBRAiRKgEQJkCgBEiVAogRIVOfvAWc+fbzcb3zr0v692KPj15X79IFnlnnC6dV7mQAnIFECJEqARAmQKAESJUCiBEhU5+8B17rFn38p91Nf3lvu29wDwv8nQKIESJQAiRIgUQIkSoBEuQfsuG3vfJV+hVY5AYkSIFECJEqARAmQKAESJUCi3APSqvnn6//v2AlIlACJEiBRAiRKgEQJkCgBEuUekFb9+cj5cncCEiVAogRIlACJEiBRAiRKgES5B2RFNo5fW+733HCy3J2ARAmQKAESJUCiBEiUAIkSIFHdvwe8uf4+WbNpuNyXLv6zmm+z5vR33Vnupx+8vNwPvrC33G8brj/vBCRKgEQJkCgBEiVAogRIlACJaiamZ5eqP7CwpX7AzkePlfvYcH2Pt1Inzm0t936vafXnX+quuexcuY9uutDqz3cCEiVAogRIlACJEiBRAiRKgEQ1k81UeQ8IbXICEiVAogRIlACJEiBRAiRKgER1/veChzZvLvefXr2j/vzF+vnjHxwt9/75dr/P2Nxdv/+ph+q//9i3/5b7yMEj9Qv068+3zQlIlACJEiBRAiRKgEQJkCgBEtX5e8Azz9X3ZIdfmy33+f5iuT/5+5vlftX+Q+W+Un+8/Xe5H79rrtzfn7++3L/4Zke5L/7wY7m3zQlIlACJEiBRAiRKgEQJkCgBEvUf7ep1cJmB6JIAAAAASUVORK5CYII=\" y=\"-22.247537\"/>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <!--  -->\r\n    <g transform=\"translate(169.728474 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-61672\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-61672\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g clip-path=\"url(#pf025844d7d)\">\r\n    <image height=\"96\" id=\"image4dce82eb83\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"243.529412\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAEJ0lEQVR4nO3dz4uUdQDHcZ+dwUUQEysNSdt+uBIiipSgByMSBIUWFiOJOpSylOEPECKQQmEDobLWS0TtiroRnUpYjYiiDq1iWkZdysYUIhI1bEEEdXb7Dz7DMA3vmd336/pBfQ5vvocvzzwWXcNvTEwLKk8cTPO0x5/fEvfpX5yOu6a2DvoBNLUZoFAGKJQBCmWAQhmgUAYoVLHurr54D/jPkTnxL1hx959xP796PO4Tt27GXZObJ6BQBiiUAQplgEIZoFAGKJQBClWsLTbGe8Ba7j05M+7fVhbFfVHfb3Efv3697mdS+/AEFMoAhTJAoQxQKAMUygCFMkChGr4HLC1ZHPelw7/G/bPjq+LetftE3c+k9uEJKJQBCmWAQhmgUAYolAEKZYBCNXwPWMvE6mVxf2bo87j3H+uNe/e+Styrly/HXSxPQKEMUCgDFMoAhTJAoQxQKAMUqtzsf6AY/Snuh3b2xP34+2/Hfd3sHXHv3uw9YCvzBBTKAIUyQKEMUCgDFMoAhTJAoZr+PmCjrm7Ovxvev/u9uL84tDXuC/pH634m/X88AYUyQKEMUCgDFMoAhTJAoQxQqKa/D9ioOwfz9wFfmpvv+U68nN8nfGxsV9znHfCesJk8AYUyQKEMUCgDFMoAhTJAoQxQqJa/B6xl4Ts/xH35A9vj/vMr++O+/mL+8zOOnoq7Mk9AoQxQKAMUygCFMkChDFAoAxSq5X8X3LCOUpwrw0vj/vqKkbgf2pq/b1j++kzcpzpPQKEMUCgDFMoAhTJAoQxQKAMUavLfA9ZQdHbGfdZXM+P+9Nzv4z74yPK4V8fG4j7ZeQIKZYBCGaBQBiiUAQplgEIZoFBT/h6wltKSxXF/+PC5uJc7xuP+S+99cb/9x8W4tztPQKEMUCgDFMoAhTJAoQxQKAMUynvABpUeuj/uVwbyJxinl6pxn7Xpatyr1/6Ne6vzBBTKAIUyQKEMUCgDFMoAhTJAobwHbLJy18K4dx6+Efcff8/vC3a/cLruZ2olnoBCGaBQBiiUAQplgEIZoFAGKJT3gLDyPfPivubL83H/8NjauD/4Wv5/SiZu3Yx7s3kCCmWAQhmgUAYolAEKZYBCGaBQ+Uerarrbf1+K+zfPPRr3Vz/+NO7vXumN+/y3RuPebJ6AQhmgUAYolAEKZYBCGaBQBiiU7wO2uRs9K+P+7L6RuA/1Pxn3Oz46Wfcz1cMTUCgDFMoAhTJAoQxQKAMUygCF8n3ANjfj6Km4fzCnJ+579h6M+8CFTXEvvjsb91o8AYUyQKEMUCgDFMoAhTJAoQxQKN8HnOyKIs5/7VoV9z19w3Ef3JC/T1g9l79v6AkolAEKZYBCGaBQBiiUAQplgEJ5D6io8ma+J/xk40DcnxrZFndPQKEMUCgDFMoAhTJAoQxQKAMU6j/Mip/e0jc0CgAAAABJRU5ErkJggg==\" y=\"-22.247537\"/>\r\n   </g>\r\n   <g id=\"text_3\">\r\n    <!-- ⁄ -->\r\n    <g transform=\"translate(290.49193 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 27.203125 74.21875 \r\nL 35.015625 74.21875 \r\nL -10.5 -1.421875 \r\nL -18.3125 -1.421875 \r\nz\r\n\" id=\"DejaVuSans-8260\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-8260\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g clip-path=\"url(#pd37ba9e98e)\">\r\n    <image height=\"96\" id=\"imagee6b9a8f150\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-137.362831\"/>\r\n   </g>\r\n   <g id=\"text_4\">\r\n    <!-- $ -->\r\n    <g transform=\"translate(51.347206 131.433419)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 33.796875 -14.703125 \r\nL 28.90625 -14.703125 \r\nL 28.859375 0 \r\nQ 23.734375 0.09375 18.609375 1.1875 \r\nQ 13.484375 2.296875 8.296875 4.5 \r\nL 8.296875 13.28125 \r\nQ 13.28125 10.15625 18.375 8.5625 \r\nQ 23.484375 6.984375 28.90625 6.9375 \r\nL 28.90625 29.203125 \r\nQ 18.109375 30.953125 13.203125 35.15625 \r\nQ 8.296875 39.359375 8.296875 46.6875 \r\nQ 8.296875 54.640625 13.625 59.21875 \r\nQ 18.953125 63.8125 28.90625 64.5 \r\nL 28.90625 75.984375 \r\nL 33.796875 75.984375 \r\nL 33.796875 64.65625 \r\nQ 38.328125 64.453125 42.578125 63.6875 \r\nQ 46.828125 62.9375 50.875 61.625 \r\nL 50.875 53.078125 \r\nQ 46.828125 55.125 42.546875 56.25 \r\nQ 38.28125 57.375 33.796875 57.5625 \r\nL 33.796875 36.71875 \r\nQ 44.875 35.015625 50.09375 30.609375 \r\nQ 55.328125 26.21875 55.328125 18.609375 \r\nQ 55.328125 10.359375 49.78125 5.59375 \r\nQ 44.234375 0.828125 33.796875 0.09375 \r\nz\r\nM 28.90625 37.59375 \r\nL 28.90625 57.625 \r\nQ 23.25 56.984375 20.265625 54.390625 \r\nQ 17.28125 51.8125 17.28125 47.515625 \r\nQ 17.28125 43.3125 20.03125 40.96875 \r\nQ 22.796875 38.625 28.90625 37.59375 \r\nz\r\nM 33.796875 28.21875 \r\nL 33.796875 7.078125 \r\nQ 39.984375 7.90625 43.140625 10.59375 \r\nQ 46.296875 13.28125 46.296875 17.671875 \r\nQ 46.296875 21.96875 43.28125 24.5 \r\nQ 40.28125 27.046875 33.796875 28.21875 \r\nz\r\n\" id=\"DejaVuSans-36\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-36\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g clip-path=\"url(#pf78338f9d8)\">\r\n    <image height=\"96\" id=\"image073bf54fd4\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"125.364706\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-137.362831\"/>\r\n   </g>\r\n   <g id=\"text_5\">\r\n    <!-- 7 -->\r\n    <g transform=\"translate(169.511912 131.433419)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-55\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_6\">\r\n   <g clip-path=\"url(#p3cd01534bc)\">\r\n    <image height=\"96\" id=\"image15861e70b5\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"243.529412\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAFXElEQVR4nO3d3WuWdQDG8T05p2zkYIRtThvO6TZbURBlowMNyW2EkQqBFgmNLHux6MCQZA0yNJEoszcWDHqBDkyIzB1EgYlMe1nopEjxUXE9a8nMjcm2NtcfUF0/Hn67d23t+zm9tmf3wZf74Mdz706tTK0by0lQbkmx3K/Ulsm9q35U7pXlGbm3VR2Ue6zWvrlybz6yWu5Lt1+U+0imO+trmkquc18ApjcChBUBwooAYUWAsCJAWBEgrFKx54DdW2rlvuuZD+Relz8U8+envLars+TefPp+uRdumy33sY5TWV/TROIOCCsChBUBwooAYUWAsCJAWBEgrFKrKrfKc8ALO/U5U+eyj8f1gpCdE8ODcl/76fNyn//NiNzz2r7L+pqywR0QVgQIKwKEFQHCigBhRYCwIkBYpaoPNMlzwMl+zrfwy8ao369+7fI4XUkyLqy5Ue7z7zsv99Bz0T2jA3Kv/fYpuS9a/5PcQ7gDwooAYUWAsCJAWBEgrAgQVgQIq9RopiLR/w8Ysj69Qu69T8+T+2R/7nWy232uXe635unvg9a8uVnuC/adlDt3QFgRIKwIEFYECCsChBUBwooAYZX4OWDo+3pLGr9P8s8j4NLjd8v9h5ffifr8xR8+KXfugLAiQFgRIKwIEFYECCsChBUBwio3dE5z+pG4c6Ci4zOjfh/J6r3zr0Q/P9QPd0BYESCsCBBWBAgrAoQVAcKKAGGVW/FKp/yBmsv6uc/OZ9+W+1Bdn76C9/WMOFceXib3dMO7E3Ql/447IKwIEFYECCsChBUBwooAYUWAsEqtTK2Lei44dfvNci966ze59w7l689/QJ8jXuvvl3tuSbHcx64vkHus0Hs+BiqGoz4/3dAS9ftJq2nfIHfugLAiQFgRIKwIEFYECCsChBUBwir6HDD4BwLnhDl7/pRzVeHvcj/WUyb3psVfyL0uf0ju0ELnfDe9OCh37oCwIkBYESCsCBBWBAgrAoQVAcIqN/YDzu7S75nY/9Drcg+9jzaohPeMxGi7OkvuW/c+JvfSN47KfTTw97kDwooAYUWAsCJAWBEgrAgQVgQIq+A5YOj/y4XfIxJ5zgcp9D7m0kMz5F549LzcizP6nC8Wd0BYESCsCBBWBAgrAoQVAcKKAGEVPAdMbfhjIq7jP50Y1s+V7uyql/uPX1WP5+X8Q1lTsudkoXPYppc+k3vLoQflPpLpzvqaxhN3QFgRIKwIEFYECCsChBUBwooAYRX9XHCs0Dnf5he2yL1g/zG5l+Uke06XtMKP2uXevHy13NN735N7+YpNcq/eob8vGHuOyB0QVgQIKwKEFQHCigBhRYCwIkBYBc8BC7cFnus9GHcBm37W75mYEzjnm+6Kjs/UP9Cg57Nr9Dnhwtn6ueMljZwDYgojQFgRIKwIEFYECCsChBUBwir6fcGpr0vl3lalDwpfvVQp98OP3iH3sY5Tcv+/231Of18w+j0sAavm3Rb1+9wBYUWAsCJAWBEgrAgQVgQIKwKEVfRzwWP3dsm94pONcj+zvFXuh/dUyH3GE4vknrS+W26Qe1d96I25WtM9n8s96XO+0HPbsbgDwooAYUWAsCJAWBEgrAgQVgQIq+jvA8b6tUV/3y/d0DJBVzI9Jf3/GUO4A8KKAGFFgLAiQFgRIKwIEFYECCv7e0KWbr8o9/JB/R6L0P+3m+6ey+hz1l8a9XPZBR3J/n9G7oCwIkBYESCsCBBWBAgrAoQVAcLK/n3AWANr75J7444Dct84p2c8LydrrX1z5d58RL8PuOBMntwX7Dsp92v9/XJPGndAWBEgrAgQVgQIKwKEFQHCigBh9Tforv1V+8luiAAAAABJRU5ErkJggg==\" y=\"-137.362831\"/>\r\n   </g>\r\n   <g id=\"text_6\">\r\n    <!-- 8 -->\r\n    <g transform=\"translate(287.676618 131.433419)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-56\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_7\">\r\n   <g clip-path=\"url(#pcea81ed163)\">\r\n    <image height=\"96\" id=\"image29fe99869b\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAD3klEQVR4nO3doW+WRwDH8b7Nm+A6g1gIGLY3IVVNMDCDIS1DTCHWCUKCASwaNV3bYUgICSsaMaBuBjAkVa9pglnCEKgqEGP7B9q7tNd7fs/g87HX53qFb05cnve9yeXJtX8XGrx4t9PyeNXFu7e6zr+09brr/JQtphfA102ARAmQKAESJUCiBEiUAImatk6w/Nud41jHgeYbm13nP7t2s+v8sxtvus7/f2cHJEqARAmQKAESJUCiBEiUAImatL4P2NviynLT8+tPtpuev770oen5R3sni+NbP682zf95Z970fJodkCgBEiVAogRIlACJEiBRAiRq9OeAabsPzxfH364+GGgl+6u9j3nm15cDreRo7IBECZAoARIlQKIESJQAiRIgUc4BG+2tXyiOv9q4P9BK9vfT7pXi+KdL7wdayf7sgEQJkCgBEiVAogRIlACJEiBRzgHDTvz5bXH86ez5QCvZX+2eltZ7VuyARAmQKAESJUCiBEiUAIkSIFHOAUeu933MrdZOrTQ9bwckSoBECZAoARIlQKIESJQAiRr9OWDrPSFjV7vno/b3P/vj9+NczqHV7kF5fO50cdwOSJQAiRIgUQIkSoBECZAoARLV/Rzwr3s/ND0/v715TCsZp9o9HzUfv/tUHE/fY1J7X9AOSJQAiRIgUQIkSoBECZAoARI1bZ2g9v1289m4z/Fq33/X2zcLn4vjtXtGaveApNX6sAMSJUCiBEiUAIkSIFECJEqARFXfBxz799ON/T7c3sb+/1NjByRKgEQJkCgBEiVAogRIlACJmu4+PF/5kZ0h1nFkX/o5X03tc8Vj/1y1HZAoARIlQKIESJQAiRIgUQIkavLP39+P+p6QH6/+Uhyv3bPxtRv7+4J2QKIESJQAiRIgUQIkSoBECZCo5u8H7M0535fNDkiUAIkSIFECJEqARAmQKAESJUCiBEiUAIkSIFECJEqARAmQKAESNa3ds/F09nygpXAUe+sXKj+xM8QyDrR2aqU4bgckSoBECZAoARIlQKIESJQAiZpW79l4N8xCDlK7x2R2481AKxmnVxv3o7+/dk/JmYWXxXE7IFECJEqARAmQKAESJUCiBEjU5PLkWvGekMWV5eIE60+2i+PXlz4cflWHULtHpCb9/YNj//d9tHeyOP743Omm+e2ARAmQKAESJUCiBEiUAIkSIFHVc8BWtff53q4+6Pnrq2rvs/U2v73Zdf6z2zebnu/9vqUdkCgBEiVAogRIlACJEiBRAiSq+zlgTf377crSn4vt7eLdW03PL229PqaV9GEHJEqARAmQKAESJUCiBEiUAIn6D06Vng2gpivbAAAAAElFTkSuQmCC\" y=\"-252.478125\"/>\r\n   </g>\r\n   <g id=\"text_7\">\r\n    <!-- ₉ -->\r\n    <g transform=\"translate(52.759081 246.548713)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 7.078125 0.5 \r\nL 7.078125 5.53125 \r\nQ 9.46875 4.546875 11.921875 4.015625 \r\nQ 14.359375 3.53125 16.703125 3.53125 \r\nQ 23 3.53125 26.3125 7.1875 \r\nQ 29.59375 10.84375 30.078125 18.375 \r\nQ 28.375 16.078125 25.4375 14.75 \r\nQ 22.65625 13.484375 19.28125 13.484375 \r\nQ 12.25 13.484375 8.140625 17.1875 \r\nQ 4.046875 20.90625 4.046875 27.359375 \r\nQ 4.046875 33.65625 8.296875 37.40625 \r\nQ 12.59375 41.21875 19.671875 41.21875 \r\nQ 27.828125 41.21875 32.078125 35.796875 \r\nQ 36.375 30.375 36.375 20.03125 \r\nQ 36.375 10.359375 31.15625 4.640625 \r\nQ 25.875 -1.109375 17 -1.109375 \r\nQ 14.59375 -1.109375 12.15625 -0.71875 \r\nQ 9.71875 -0.28125 7.078125 0.5 \r\nz\r\nM 19.671875 17.78125 \r\nQ 23.96875 17.78125 26.453125 20.3125 \r\nQ 28.953125 22.859375 28.953125 27.359375 \r\nQ 28.953125 31.75 26.46875 34.28125 \r\nQ 23.96875 36.875 19.671875 36.875 \r\nQ 15.53125 36.875 12.9375 34.28125 \r\nQ 10.40625 31.75 10.40625 27.359375 \r\nQ 10.40625 22.859375 12.9375 20.328125 \r\nQ 15.4375 17.78125 19.671875 17.78125 \r\nz\r\n\" id=\"DejaVuSans-8329\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-8329\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_8\">\r\n   <g clip-path=\"url(#pcdf88ff8a0)\">\r\n    <image height=\"96\" id=\"image7fc17049a4\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"125.364706\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAGBUlEQVR4nO3dXUxWBQDGcV94we/IBmJlGhkvkun8qjSL6WCEOXE2NVpFVNur5SxttWazeaVuuXQqmpFmmri2ytILq5WrtgxL3cgPNFDMahRpmiJTkVe67uY5cyd9RP6/2wePx+3vuTg7nBOprL2nrZNQ0vOUmgPF1j8n96y5VXJvzR8h9zXvLtPHT+kh9/yaYrmnFDXIva21Ve7QktwngI6NAGFFgLAiQFgRIKwIEFYECKtIzrwl8j5gzcxVof6Ctaf7yP3jvMFyTxw/Lvfkr2+R+7acbXIPUjTxcbm37TkQ6vgdHVdAWBEgrAgQVgQIKwKEFQHCigBhFb19xX75A7XxZrnHUrrL/dm0P+VePu0Rufdeqe8DnqroJ/ezi8/LvUdSF7kffilV7gP0bUIE4AoIKwKEFQHCigBhRYCwIkBYESCsIgWRKfJ5wNrV98oDHC2uCHUCs/8YKfdDo/T/kbaLLXIv2N8k91duOiL3IOOzx8j9UrO+j9rRcQWEFQHCigBhRYCwIkBYESCsCBBWgfcBkzMy5AFKv9st97DvFxy04nm59130vdzPTdL3MTeXL5V7erJ+3nHYrhK59550SO4dHVdAWBEgrAgQVgQIKwKEFQHCigBhFXgfMEj9G6PlXvfEW2EO3+m1xiFyry5Il3vi75Nyz97VWe7lt/4g9xMJ/bxf6UNPyz1RUyv36x1XQFgRIKwIEFYECCsChBUBwooAYRUNe4DsNX/Jfe80/X6+Ian6/XwLM/fKfVTRDLmnVe6Ue9U7w+V+cb5+3jDoecGDs26Ue0x/Tvm6xxUQVgQIKwKEFQHCigBhRYCwIkBYhX4eMEj9pqFyrxv7XqjjF9cVyb2lUP9ectuFC3J/4bD+vd4J3fR9zj0X9PsLXx+pzz/oecb2jisgrAgQVgQIKwKEFQHCigBhRYCwCv08YJCslXo/mxfue75bsz+Xe+HIMrlHdlTL/eWNz8h9QnyV3Ed01t8bPhYfKPeg9x+2d1wBYUWAsCJAWBEgrAgQVgQIKwKE1RV/HjBI52/7yD3oPl+Q3B1Pyr3f1H2hjv9FQ3WoP7/hjH6/YeXAvqGOf63jCggrAoQVAcKKAGFFgLAiQFgRIKwCnwdM6qKfx/tn8lC5Nz6gbzMOTzoSdAqhHBzzvtwnZE2Se+vRY3K/45Ppcq+f/LbcS284Ifdl8alyT6+okvu1jisgrAgQVgQIKwKEFQHCigBhRYCwiiYPypE/kLuhTu5v3rz6/zyfq67m1Uy5x2bo+4C5i37Xf8Hkyz2j/xoT3y33nyvCHd+NKyCsCBBWBAgrAoQVAcKKAGFFgLCKZG1aIB/YOzxu3dU6F4vai81ynz14vNwTTU1yb9icK/d9922S++lL5+Q+ceaLcu+65Ue5u3EFhBUBwooAYUWAsCJAWBEgrAgQVtGdeeUBP9L9qpyISyxF//t+mXW33G9boL/jkblc/151p0o9pyV1lfv5uP4ectct+vhuXAFhRYCwIkBYESCsCBBWBAgrAoRVpP+qxfJ5wKD3213vPmjqJfd1Of3lHvR+xe5f9pD7RwO+kvuBFv284JzHZsg9UvWT3K80roCwIkBYESCsCBBWBAgrAoQVAcIq2n9rQv9EyPfbtXclPfXzdkueKpF7r/X6Ox6/rh2mT2Chvg84KFU/L1hXlir3mPkzI1wBYUWAsCJAWBEgrAgQVgQIKwKEVaQgMkW/H3DpKHmAI4+27++EhFV6LE/ujaPPyD05I0Pu92//Te7z0g/J/dNm/bxhxcOFck/U1cs9LK6AsCJAWBEgrAgQVgQIKwKEFQHCKvA+YCQalQeo33iX3GvzNlz+WbUjQd/xGP7hnFDHn134mdxn9dLfMw5y5zdlcm9rDHi/YYDY3Gq5cwWEFQHCigBhRYCwIkBYESCsCBBWgfcBgyR16yb308VD5F42f6vc42kNl31OuHY8OHO63LkCwooAYUWAsCJAWBEgrAgQVgQIq9D3AcOK9smU+8lxWXJvLGqR+/axy+WelaJ/bxbh5NcUy50rIKwIEFYECCsChBUBwooAYUWAsPoXaCkhoEBZNywAAAAASUVORK5CYII=\" y=\"-252.478125\"/>\r\n   </g>\r\n   <g id=\"text_8\">\r\n    <!-- ¶ -->\r\n    <g transform=\"translate(169.511912 246.548713)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 30.90625 72.90625 \r\nL 52.78125 72.90625 \r\nL 52.78125 -9.625 \r\nL 45.90625 -9.625 \r\nL 45.90625 66.890625 \r\nL 36.625 66.890625 \r\nL 36.625 -9.625 \r\nL 29.6875 -9.625 \r\nL 29.6875 31.6875 \r\nQ 19.1875 32.515625 13.453125 37.90625 \r\nQ 7.71875 43.3125 7.71875 52.296875 \r\nQ 7.71875 61.578125 14.0625 67.234375 \r\nQ 20.40625 72.90625 30.90625 72.90625 \r\nz\r\n\" id=\"DejaVuSans-182\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-182\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_9\">\r\n   <g clip-path=\"url(#pd655e7ad09)\">\r\n    <image height=\"96\" id=\"image3adf3a6a99\" transform=\"scale(1 -1)translate(0 -96)\" width=\"96\" x=\"243.529412\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-252.478125\"/>\r\n   </g>\r\n   <g id=\"text_9\">\r\n    <!-- ౄ -->\r\n    <g transform=\"translate(287.89318 246.548713)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-3140\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-3140\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pbba00f5536\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"7.2\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p32c94287bf\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"125.364706\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf025844d7d\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"243.529412\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd37ba9e98e\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"7.2\" y=\"137.433419\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf78338f9d8\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"125.364706\" y=\"137.433419\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p3cd01534bc\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"243.529412\" y=\"137.433419\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pcea81ed163\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"7.2\" y=\"252.548713\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pcdf88ff8a0\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"125.364706\" y=\"252.548713\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd655e7ad09\">\r\n   <rect height=\"95.929412\" width=\"95.929412\" x=\"243.529412\" y=\"252.548713\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "  plt.subplot(3,3,n+1)\n",
    "  plt.imshow(features['image'][..., n])\n",
    "  plt.title(chr(features['m_label'][n]))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-nNR0Nncdd1"
   },
   "source": [
    "## Lower level functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jiGZeUijJNd"
   },
   "source": [
    "So far this tutorial has focused on the highest level utilities for reading csv data. There are other two APIs that may be helpful for advanced users if your use-case doesn't fit the basic patterns.\n",
    "\n",
    "* `tf.io.decode_csv` - a function for parsing lines of text into a list of CSV column tensors.\n",
    "* `tf.data.experimental.CsvDataset` - a lower level csv dataset constructor.\n",
    "\n",
    "This section recreates functionality provided by `make_csv_dataset`, to demonstrate how this lower level functionality can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_ixywomOHW"
   },
   "source": [
    "### `tf.io.decode_csv`\n",
    "\n",
    "This function decodes a string, or list of strings into a list of columns.\n",
    "\n",
    "Unlike `make_csv_dataset` this function does not try to guess column data-types. You specify the column types by providing a list of `record_defaults` containing a value of the correct type, for each column.\n",
    "\n",
    "To read the Titanic data **as strings** using `decode_csv` you would say: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.426996Z",
     "iopub.status.busy": "2020-11-18T02:26:04.426233Z",
     "iopub.status.idle": "2020-11-18T02:26:04.429762Z",
     "shell.execute_reply": "2020-11-18T02:26:04.429145Z"
    },
    "id": "m1D2C-qdlqeW"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.434623Z",
     "iopub.status.busy": "2020-11-18T02:26:04.433958Z",
     "iopub.status.idle": "2020-11-18T02:26:04.464267Z",
     "shell.execute_reply": "2020-11-18T02:26:04.464726Z"
    },
    "id": "9W4UeJYyHPx5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8TaHSQFoQL4"
   },
   "source": [
    "To parse them with their actual types, create a list of `record_defaults` of the corresponding types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.469338Z",
     "iopub.status.busy": "2020-11-18T02:26:04.468648Z",
     "iopub.status.idle": "2020-11-18T02:26:04.471887Z",
     "shell.execute_reply": "2020-11-18T02:26:04.471150Z"
    },
    "id": "rzUjR59yoUe1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.476930Z",
     "iopub.status.busy": "2020-11-18T02:26:04.476234Z",
     "iopub.status.idle": "2020-11-18T02:26:04.479660Z",
     "shell.execute_reply": "2020-11-18T02:26:04.479122Z"
    },
    "id": "7sPTunxwoeWU"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.484380Z",
     "iopub.status.busy": "2020-11-18T02:26:04.483707Z",
     "iopub.status.idle": "2020-11-18T02:26:04.489997Z",
     "shell.execute_reply": "2020-11-18T02:26:04.489476Z"
    },
    "id": "n3NlViCzoB7F"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type: int32, shape: (627,)\ntype: string, shape: (627,)\ntype: float32, shape: (627,)\ntype: int32, shape: (627,)\ntype: int32, shape: (627,)\ntype: float32, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\ntype: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-LkTUTnpn2P"
   },
   "source": [
    "Note: it is more efficient to call `decode_csv` on large batches of lines than on individual lines of csv text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp1UItJmqGqw"
   },
   "source": [
    "### `tf.data.experimental.CsvDataset`\n",
    "\n",
    "The `tf.data.experimental.CsvDataset` class provides a minimal CSV `Dataset` interface without the convenience features of the `make_csv_dataset` function: column header parsing, column type-inference, automatic shuffling, file interleaving.\n",
    "\n",
    "This constructor follows uses `record_defaults` the same way as `io.parse_csv`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.495281Z",
     "iopub.status.busy": "2020-11-18T02:26:04.494608Z",
     "iopub.status.idle": "2020-11-18T02:26:04.502408Z",
     "shell.execute_reply": "2020-11-18T02:26:04.502814Z"
    },
    "id": "9OzZLp3krP-t"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HBmfI-Ks7dw"
   },
   "source": [
    "The above code is basically equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.508869Z",
     "iopub.status.busy": "2020-11-18T02:26:04.507983Z",
     "iopub.status.idle": "2020-11-18T02:26:04.710149Z",
     "shell.execute_reply": "2020-11-18T02:26:04.710553Z"
    },
    "id": "E5O5d69Yq7gG"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "  return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R3ralsnt2AC"
   },
   "source": [
    "#### Multiple files\n",
    "\n",
    "To parse the fonts dataset using `experimental.CsvDataset`, you first need to determine the column types for the `record_defaults`. Start by inspecting the first row of one file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.714905Z",
     "iopub.status.busy": "2020-11-18T02:26:04.714262Z",
     "iopub.status.idle": "2020-11-18T02:26:04.720431Z",
     "shell.execute_reply": "2020-11-18T02:26:04.719900Z"
    },
    "id": "3tlFOTjCvAI5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etyGu8K_ySRz"
   },
   "source": [
    "Only the first two fields are strings, the rest are ints or floats, and you can get the total number of features by counting the commas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.724976Z",
     "iopub.status.busy": "2020-11-18T02:26:04.724334Z",
     "iopub.status.idle": "2020-11-18T02:26:04.726300Z",
     "shell.execute_reply": "2020-11-18T02:26:04.726720Z"
    },
    "id": "crgZZn0BzkSB"
   },
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeK2Pw540RNj"
   },
   "source": [
    "The `CsvDatasaet` constructor can take a list of input files, but reads them sequentially. The first file in the list of CSVs is `AGENCY.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.731168Z",
     "iopub.status.busy": "2020-11-18T02:26:04.730489Z",
     "iopub.status.idle": "2020-11-18T02:26:04.733527Z",
     "shell.execute_reply": "2020-11-18T02:26:04.732927Z"
    },
    "id": "_SvL5Uvl0r0N"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'fonts\\\\AGENCY.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfAX3G8Xywy6"
   },
   "source": [
    "So when you pass pass the list of files to `CsvDataaset` the records from `AGENCY.csv` are read first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.747092Z",
     "iopub.status.busy": "2020-11-18T02:26:04.746386Z",
     "iopub.status.idle": "2020-11-18T02:26:04.749561Z",
     "shell.execute_reply": "2020-11-18T02:26:04.748978Z"
    },
    "id": "Gtr1E66VmBqj"
   },
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.756060Z",
     "iopub.status.busy": "2020-11-18T02:26:04.755315Z",
     "iopub.status.idle": "2020-11-18T02:26:04.834916Z",
     "shell.execute_reply": "2020-11-18T02:26:04.835369Z"
    },
    "id": "k750Mgq4yt_o"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "  print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiqWKQV21FrE"
   },
   "source": [
    "To interleave multiple files, use `Dataset.interleave`.\n",
    "\n",
    "Here's an initial dataset that contains the csv file names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.840144Z",
     "iopub.status.busy": "2020-11-18T02:26:04.839379Z",
     "iopub.status.idle": "2020-11-18T02:26:04.846324Z",
     "shell.execute_reply": "2020-11-18T02:26:04.845780Z"
    },
    "id": "t9dS3SNb23W8"
   },
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNiLHMXpzHy5"
   },
   "source": [
    "This shuffles the file names each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.851773Z",
     "iopub.status.busy": "2020-11-18T02:26:04.851068Z",
     "iopub.status.idle": "2020-11-18T02:26:04.875181Z",
     "shell.execute_reply": "2020-11-18T02:26:04.875599Z"
    },
    "id": "zNd-TYyNzIgg"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1:\n     b'fonts\\\\FELIX TITLING.csv'\n     b'fonts\\\\MV_BOLI.csv'\n     b'fonts\\\\FREESTYLE.csv'\n     b'fonts\\\\MONOSPAC821.csv'\n     b'fonts\\\\ERAS.csv'\n    ...\n\nEpoch 2:\n     b'fonts\\\\CENTAUR.csv'\n     b'fonts\\\\HANDPRINT.csv'\n     b'fonts\\\\ROCKWELL.csv'\n     b'fonts\\\\CREDITCARD.csv'\n     b'fonts\\\\ENGLISH.csv'\n    ...\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0QB1PtU3WAN"
   },
   "source": [
    "The `interleave` method takes a `map_func` that creates a child-`Dataset` for each element of the parent-`Dataset`. \n",
    "\n",
    "Here, you want to create a `CsvDataset` from each element of the dataset of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.879960Z",
     "iopub.status.busy": "2020-11-18T02:26:04.879268Z",
     "iopub.status.idle": "2020-11-18T02:26:04.881320Z",
     "shell.execute_reply": "2020-11-18T02:26:04.881741Z"
    },
    "id": "QWp4rH0Q4uPh"
   },
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "  return tf.data.experimental.CsvDataset(\n",
    "    path, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxRGdLMB5nRF"
   },
   "source": [
    "The `Dataset` returned by interleave returns elements by cycling over a number of the child-`Dataset`s. Note, below, how the dataset cycles over `cycle_length)=3` three font files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:04.907113Z",
     "iopub.status.busy": "2020-11-18T02:26:04.895248Z",
     "iopub.status.idle": "2020-11-18T02:26:05.076553Z",
     "shell.execute_reply": "2020-11-18T02:26:05.077075Z"
    },
    "id": "OePMNF_x1_Cc"
   },
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds,\n",
    "                                  cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:05.084549Z",
     "iopub.status.busy": "2020-11-18T02:26:05.083835Z",
     "iopub.status.idle": "2020-11-18T02:26:05.207482Z",
     "shell.execute_reply": "2020-11-18T02:26:05.206772Z"
    },
    "id": "UORIGWLy54-E"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    font_name character\n",
       "0     VERDANA         �\n",
       "1     BOOKMAN         ﬂ\n",
       "2  CONSTANTIA         ﬄ\n",
       "3     VERDANA         ￦\n",
       "4     BOOKMAN         ﬁ\n",
       "5  CONSTANTIA         ﬃ\n",
       "6     VERDANA         ￥\n",
       "7     BOOKMAN         \n",
       "8  CONSTANTIA         ﬂ\n",
       "9     VERDANA         ﬗ"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>font_name</th>\n      <th>character</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>VERDANA</td>\n      <td>�</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BOOKMAN</td>\n      <td>ﬂ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CONSTANTIA</td>\n      <td>ﬄ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>VERDANA</td>\n      <td>￦</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BOOKMAN</td>\n      <td>ﬁ</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CONSTANTIA</td>\n      <td>ﬃ</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>VERDANA</td>\n      <td>￥</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>BOOKMAN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CONSTANTIA</td>\n      <td>ﬂ</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>VERDANA</td>\n      <td>ﬗ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "  fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "  fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkKZa_HX8zAm"
   },
   "source": [
    "#### Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BtGHraUApdJ"
   },
   "source": [
    "Earlier, it was noted that `io.decode_csv` is more efficient when run on a batch of strings.\n",
    "\n",
    "It is possible to take advantage of this fact, when using large batch sizes, to improve CSV loading performance (but try [caching](#caching) first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d35zWMH7MDL1"
   },
   "source": [
    "With the built-in loader 20, 2048-example batches take about 17s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:05.213005Z",
     "iopub.status.busy": "2020-11-18T02:26:05.212303Z",
     "iopub.status.idle": "2020-11-18T02:26:06.091474Z",
     "shell.execute_reply": "2020-11-18T02:26:06.090863Z"
    },
    "id": "ieUVAPryjpJS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:06.098791Z",
     "iopub.status.busy": "2020-11-18T02:26:06.098112Z",
     "iopub.status.idle": "2020-11-18T02:26:17.770343Z",
     "shell.execute_reply": "2020-11-18T02:26:17.769647Z"
    },
    "id": "MUC2KW4LkQIz"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "....................\n",
      "Wall time: 9.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lhnh6rZEDS2"
   },
   "source": [
    "Passing **batches of text lines** to`decode_csv` runs faster, in about 5s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:17.776986Z",
     "iopub.status.busy": "2020-11-18T02:26:17.776033Z",
     "iopub.status.idle": "2020-11-18T02:26:18.210503Z",
     "shell.execute_reply": "2020-11-18T02:26:18.209735Z"
    },
    "id": "4XbPZV1okVF9"
   },
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T02:26:18.218653Z",
     "iopub.status.busy": "2020-11-18T02:26:18.217809Z",
     "iopub.status.idle": "2020-11-18T02:26:23.063469Z",
     "shell.execute_reply": "2020-11-18T02:26:23.062911Z"
    },
    "id": "te9C2km-qO8W"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "....................\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aebC1plsMeOi"
   },
   "source": [
    "For another example of increasing csv performance by using large batches see the [overfit and underfit tutorial](../keras/overfit_and_underfit.ipynb).\n",
    "\n",
    "This sort of approach may work, but consider other options like `cache` and `snapshot`, or re-enncoding your data into a more streamlined format."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "csv.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c3443d71a09b0ca4f34db27e6367b1b40469ecb42f97c2a3ce73ac89d80306cf"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}